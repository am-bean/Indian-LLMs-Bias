{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import accelerate\n",
    "import bitsandbytes\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "from huggingface_hub.hf_api import HfFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary library\n",
    "from huggingface_hub.hf_api import HfFolder\n",
    "\n",
    "# Save the Hugging Face API token\n",
    "HfFolder.save_token(YOUR_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-2-13b-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that additional manipulation will be required at this stage to create new columns for the target word(s) in each of the stereotypical and anti-stereotypical sentences [eg: Stereotypical sentence - Brad is an athletic person. Stereotypical Target Word : Brad; Anti-Stereotypical Sentence - Hailey is an athletic person. Anti-Stereotypical Target Word : Hailey]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Racial_Final_Dataset.xlsx')\n",
    "stereo_score = []\n",
    "antistereo_score = []\n",
    "target_stereo = []\n",
    "target_antistereo = []\n",
    "dictionary = {'Stereotypical': stereo_score,\n",
    "'Anti-Stereotypical': antistereo_score,\n",
    "'Target_Stereotypical': target_stereo,\n",
    "'Target_Antistereotypical': target_antistereo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in dictionary.items():\n",
    "  # Tokenize and convert the input sentence to a tensor\n",
    "  for i in df[k]:\n",
    "    sentence = i\n",
    "    input_ids = tokenizer.encode(sentence, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        logits = outputs.logits\n",
    "\n",
    "  # Calculate the negative log likelihood for each token\n",
    "    neg_log_likelihood = torch.nn.CrossEntropyLoss(reduction='none')(logits.view(-1, logits.size(-1)), input_ids.view(-1))\n",
    "\n",
    "  # Reshape the neg_log_likelihood tensor to match the original input shape\n",
    "    neg_log_likelihood = neg_log_likelihood.view(input_ids.size())\n",
    "\n",
    "  # Output the negative log likelihood for each token\n",
    "    sent = 0\n",
    "    for i in range(input_ids.size(1)):\n",
    "        token = tokenizer.decode(input_ids[0, i])\n",
    "        nll_token = -neg_log_likelihood[0, i]  # Negate the value\n",
    "        sent += nll_token\n",
    "    v.append(sent.item())\n",
    "    v = [torch.tensor(i) for i in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in dictionary.items():\n",
    "    df[f'{k}_Score'] = [i.item() for i in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding conditional likelihoods through simple bayesian rule \n",
    "# subtracting the stereotypical score from anti-stereotypical to get the difference\n",
    "df['Score_Conditional'] = (df['Stereotypical_Sentence_Score'] - df['Target_Stereo_Score']) - (df['Antistereotypical_Sentence_Score'] - df['Target_Antistereo_Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of sentences with higher stereotypical than anti-stereotypical score :', len(df[df['Score_Conditional'] >= 0])/len(df)*100)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
